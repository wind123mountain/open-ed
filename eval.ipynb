{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06654112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "gt_all = []\n",
    "gt_trigger = []\n",
    "with open(\"processed_data/ace/qwen/test.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        events = json.loads(json.loads(line)['response'])['events']\n",
    "        e_gt = []\n",
    "        triggers = []\n",
    "        for trigger in events:\n",
    "            e_gt.append(str((trigger['trigger_text'], [(arg['text'], arg['role']) for arg in trigger['arguments']])))\n",
    "            triggers.append(str((trigger['trigger_text'], trigger['type'])))\n",
    "        gt_all.append(e_gt)\n",
    "        gt_trigger.append(triggers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8511890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "pred_trigger = []\n",
    "with open(\"eval_outputs/VoCuc/Qwen3-4B-ace-sft/ace_answers.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        events = json.loads(json.loads(line)['text'])['events']\n",
    "        e_pred = []\n",
    "        triggers = []\n",
    "        for trigger in events:\n",
    "            e_pred.append(str((trigger['trigger_text'], [(arg['text'], arg['role']) for arg in trigger['arguments']])))\n",
    "            triggers.append(str((trigger['trigger_text'], trigger['type'])))\n",
    "        pred.append(e_pred)\n",
    "        pred_trigger.append(triggers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e6050c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"('previous', [('Barriers Bank', 'Entity'), ('BZW', 'Entity'), ('Kleinwort Benson', 'Entity'), ('McCarthy', 'Entity')])\"]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7527794a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['previous']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_trigger[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c873db60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,) (4, 768)\n",
      "tensor([[0.3008, 0.6361, 0.4927, 0.4889]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Download from the ðŸ¤— Hub\n",
    "model = SentenceTransformer(\"google/embeddinggemma-300m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e9f3aa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "threshold = 0.88\n",
    "all_similarities = []\n",
    "\n",
    "for p, gt in zip(pred, gt_all):\n",
    "    try:\n",
    "        p_embeddings = model.encode(p)\n",
    "        gt_embeddings = model.encode(gt)\n",
    "        similarities = model.similarity(p_embeddings, gt_embeddings)\n",
    "        all_similarities.append(similarities)\n",
    "        acc += (similarities.max(-1).values > threshold).sum()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d519b033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  tensor(0.4818)\n",
      "recall:  tensor(0.4591)\n"
     ]
    }
   ],
   "source": [
    "print(\"precision: \", acc / sum(len(sublist) for sublist in pred))\n",
    "print(\"recall: \", acc / sum(len(sublist) for sublist in gt_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4baece29",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "threshold = 0.88\n",
    "all_similarities = []\n",
    "\n",
    "for p, gt in zip(pred_trigger, gt_trigger):\n",
    "    try:\n",
    "        p_embeddings = model.encode(p)\n",
    "        gt_embeddings = model.encode(gt)\n",
    "        similarities = model.similarity(p_embeddings, gt_embeddings)\n",
    "        all_similarities.append(similarities)\n",
    "        acc += (similarities.max(-1).values > threshold).sum()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a789d0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  tensor(0.7578)\n",
      "recall:  tensor(0.7221)\n"
     ]
    }
   ],
   "source": [
    "print(\"precision: \", acc / sum(len(sublist) for sublist in pred))\n",
    "print(\"recall: \", acc / sum(len(sublist) for sublist in gt_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd0dd16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ad-sampling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
